{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done adding path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "_path = os.path.abspath('../')\n",
    "if _path not in sys.path:\n",
    "    sys.path.insert(0, _path)\n",
    "print('done adding path')\n",
    "    \n",
    "import astropy.coordinates as coord\n",
    "import numpy as np\n",
    "from gala.units import UnitSystem\n",
    "from yellowcard.model import TimingArgumentModel \n",
    "from yellowcard.coordinates import fiducial_m31_c,LocalGroupHalocentric\n",
    "import astropy.units as u\n",
    "from scipy.optimize import minimize\n",
    "from yellowcard.keplerianPlane import LGKepler\n",
    "from numpy.linalg import norm\n",
    "import emcee\n",
    "import arviz as az\n",
    "from schwimmbad import MultiPool \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import corner\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelChoice = \"vdm2012-radial\"\n",
    "# modelChoice = \"vdm2012\"\n",
    "# modelChoice = \"fiducial2021\"\n",
    "modelChoice = \"apw-simulated\"\n",
    "# modelChoice = \"apw-simulated-precise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimingArgumentModel.from_dataset(f\"../datasets/{modelChoice}.ecsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "galcen_m31     = fiducial_m31_c.transform_to(model.galcen_frame)\n",
    "galcen_m31_pos = galcen_m31.data.without_differentials()\n",
    "galcen_m31_vel = galcen_m31.velocity\n",
    "galcen_m31_L   = galcen_m31_pos.cross(galcen_m31_vel)\n",
    "galcen_m31_L   = galcen_m31_L / galcen_m31_L.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_init   = 0.9\n",
    "eta_init = 5*u.rad\n",
    "alpha_init = 0*u.rad\n",
    "init_par = {}\n",
    "\n",
    "init_par['lnr'] = np.log(fiducial_m31_c.distance.value)\n",
    "init_par['eParam'] = -3\n",
    "init_par['coseta'] = np.cos(eta_init)\n",
    "init_par['sineta'] = np.sin(eta_init)\n",
    "init_par['lnM'] = np.log((4e12*u.Msun).decompose(model.unit_system).value)\n",
    "# init_par['Lhatlg'] = galcen_m31_L.xyz\n",
    "init_par['cosalpha'] = np.cos(alpha_init)\n",
    "init_par['sinalpha'] = np.sin(alpha_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.594413459749778"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_par['lnr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3862943611198904"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_par['lnM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Quantity -37198.49752638>,\n",
       " [-167.26772405506136,\n",
       "  57.20133852792108,\n",
       "  134.09224084945131,\n",
       "  727.0600850834467])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.ln_posterior(init_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## creating first minimization of MCMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize( lambda *args: -model(*args)[0], model.pack_pars(init_par), method='Powell')\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   direc: array([[ 0.04676432, -0.16085979, -0.0444698 ,  0.34947354,  0.0441102 ,\n",
       "        -0.07602833, -0.08143019],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.03974525, -0.01994406, -0.04011197,  0.56328236,  0.0394432 ,\n",
       "        -0.09291165, -0.24267954]])\n",
       "     fun: 155.82642152070437\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 1044\n",
       "     nit: 10\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([ 6.45900402, -1.28234769, -0.17475095, -0.47922012,  1.60943791,\n",
       "        4.48956904, -2.20059519])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "# MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = 8*len(result.x)\n",
    "sampler_x0 = np.random.normal(result.x, 1e-1, size=(nwalkers,len(result.x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 877/1000 [01:52<00:16,  7.47it/s]"
     ]
    }
   ],
   "source": [
    "with MultiPool() as pool:\n",
    "    sampler = emcee.EnsembleSampler(nwalkers=nwalkers, \n",
    "                                    ndim=len(result.x), \n",
    "                                    log_prob_fn=model, \n",
    "                                    pool=pool,\n",
    "                                    blobs_dtype=model.blobs_dtype)\n",
    "\n",
    "    # burn in #1\n",
    "    state = sampler.run_mcmc(sampler_x0, \n",
    "                     nsteps=1000, \n",
    "                     progress=True)  # burn in\n",
    "#     chain_meds = np.median(sampler.chain[:, -1],\n",
    "#                            axis=0)\n",
    "#     new_x0s = np.random.normal(chain_meds, 1e-2, size=(nwalkers, len(result.x)))\n",
    "#     sampler.reset()\n",
    "# #     print(\"done with first burn in\")\n",
    "    \n",
    "#     # burn in #2 \n",
    "#     state = sampler.run_mcmc(new_x0s, \n",
    "#                              nsteps=1000,\n",
    "#                              progress=True)\n",
    "    sampler.reset()\n",
    "#     print(\"done with second burn in\")\n",
    "    \n",
    "    # main mcmc run\n",
    "    state = sampler.run_mcmc(state, \n",
    "                             nsteps=2000, \n",
    "                             progress=True)\n",
    "#     print(\"done with chain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## creating list of means of each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everyHundo = np.vstack(sampler.chain[:, ::100])\n",
    "allOfThem = np.vstack(sampler.chain[:, ::])\n",
    "\n",
    "subsample = {}\n",
    "sample = {}\n",
    "col_names = [\"lnr\",\"eParam\", \"coseta\", \"sineta\", \"lnM\", \"cosalpha\", \"sinalpha\"]\n",
    "for i in range(len(col_names)):\n",
    "    subsample[col_names[i]] = everyHundo[:,i]\n",
    "    sample[col_names[i]] = allOfThem[:,i]\n",
    "    \n",
    "model_params = np.vstack([model.transform_pars(sample)[key] for key, values in model.transform_pars(sample).items()]).T\n",
    "model_params_subsample = np.vstack([model.transform_pars(subsample)[key] for key, values in model.transform_pars(subsample).items()]).T\n",
    "\n",
    "means = {}\n",
    "for key, values in model.transform_pars(sample).items():\n",
    "    means[key] = np.mean(model.transform_pars(sample)[key]) \n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everyHundo = np.vstack(sampler.chain[:, ::100])\n",
    "allOfThem = np.vstack(sampler.chain[:, ::])\n",
    "blobs = sampler.get_blobs()\n",
    "\n",
    "subsample = {}\n",
    "sample = {}\n",
    "blobSample = {}\n",
    "col_names = [\"lnr\",\"eParam\", \"coseta\", \"sineta\", \"lnM\", \"cosalpha\", \"sinalpha\"]\n",
    "for i in range(len(col_names)):\n",
    "    subsample[col_names[i]] = everyHundo[:,i]\n",
    "    sample[col_names[i]] = allOfThem[:,i]\n",
    "\n",
    "for i in blobs.dtype.names:\n",
    "    blobSample[i] = blobs[i].flatten()\n",
    "    \n",
    "model_params = np.vstack([model.transform_pars(sample)[key] for key, values in model.transform_pars(sample).items()]+\n",
    "                        [blobSample[key] for key, values in blobSample.items()]).T\n",
    "\n",
    "means = {}\n",
    "for key, values in model.transform_pars(sample).items():\n",
    "    means[key] = np.mean(model.transform_pars(sample)[key]) \n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['lnr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobSample.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(model.transform_pars(subsample)['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(model.transform_pars(subsample)['M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## figures for full sampled set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tulips = az.from_emcee(sampler,\n",
    "                       var_names=[\"ln r\",\"ln(1-e)\", \"coseta\", \"sineta\", \"ln M\", \"cosalpha\", \"sinalpha\"])\n",
    "lookout = az.convert_to_inference_data(model.transform_pars(sample))\n",
    "looks = az.convert_to_dataset(lookout).to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = az.plot_trace(tulips);\n",
    "# fig.suptitle(model.title,fontsize=20)\n",
    "plt.savefig(f\"../plots/{modelChoice}-trace.png\")\n",
    "\n",
    "az.plot_pair(tulips);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(np.vstack(sampler.chain[:, ::]),\n",
    "                    labels=[\"ln r\",\"ln(1-e)\", \"coseta\", \"sineta\", \"ln M\", \"cosalpha\", \"sinalpha\"],\n",
    "                    show_titles=True)\n",
    "ii = 0\n",
    "fig.text(0.8, 0.63,\"Means\",fontsize=20)\n",
    "for key, val in means.items():\n",
    "    try:\n",
    "        val = val.value\n",
    "    except AttributeError:\n",
    "        val = val\n",
    "    fig.text(0.8,0.6-0.02*ii,key+\"=%.2f\" % val,fontsize=20)\n",
    "    ii+=1\n",
    "fig.suptitle(model.title,fontsize=20)\n",
    "plt.savefig(f\"../plots/{modelChoice}-parametrizedCorner.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truths = {\n",
    "    'r': 711.91702,\n",
    "    'M': 3.8,\n",
    "    'eta': 4.3,\n",
    "    'tperi': 14.524635,\n",
    "    'alpha': 0.56548,\n",
    "    'e': 0.981,\n",
    "    'a': 511,\n",
    "    'vscale': 182.9,\n",
    "    'vrad': -118,\n",
    "    'vtan': 25.47,\n",
    "    'sunToM31': 707.9769\n",
    "}\n",
    "\n",
    "fig = corner.corner(model_params,\n",
    "                    labels=[\"r\",\"e\", \"eta\", \"M\", \"alpha\",\"vrad\",\"vtan\",\"vscale\",\"sunToM31\"],\n",
    "#                     truths=truths,\n",
    "                    show_titles=True);\n",
    "# ii = 0\n",
    "# fig.text(0.8, 0.63,\"Means\",fontsize=20)\n",
    "# for key, val in means.items():\n",
    "#     try:\n",
    "#         val = val.value\n",
    "#         val = val\n",
    "#     fig.text(0.8,0.6-0.02*ii,key+\"=%.2f\" % val,fontsize=20)\n",
    "#     ii+=1\n",
    "fig.suptitle(model.title,fontsize=20)\n",
    "plt.savefig(f\"../plots/{modelChoice}-modelCorner.png\",transparent=False,facecolor=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## the plots below are for the transformed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(lookout);\n",
    "az.plot_pair(lookout);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = sampler.get_blobs()\n",
    "plt.hist(np.ravel(blobs['sunToM31'][::10]),20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs.dtype.names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist2d(np.ravel(blobs['sunToM31'][::10]), model.whats_this(lil)['r'],bins=64)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## some extra testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corner.corner(model_params,\n",
    "#               labels=[\"r\",\"e\", \"eta\", \"M\", \"alpha\"],\n",
    "#               show_titles=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanies = np.mean(np.vstack(sampler.chain[:, ::100]), axis=0)\n",
    "# whats_this_mean(model.unpack_pars(meanies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats_this(par_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def whats_this_mean(par_dict):\n",
    "# #         ''' you can tell that i hard coded this function :) '''\n",
    "# #         what_dict = {}\n",
    "# #         what_dict['r'] = np.mean(np.exp(par_dict['lnr']))*u.kpc\n",
    "# #         what_dict['e'] = np.mean(1 - np.exp(par_dict['eParam']))\n",
    "# #         etta = np.arctan2(par_dict['sineta'],par_dict['coseta']) # *u.rad\n",
    "# #         what_dict['eta'] = np.mean(etta%(2*np.pi))\n",
    "# #         what_dict['M'] = np.mean(np.exp(par_dict['lnM'])*model.unit_system['mass'])\n",
    "# #         allpha = np.arctan2(par_dict['sinalpha'],par_dict['cosalpha']) # *u.rad\n",
    "# #         what_dict['alpha'] = np.mean(allpha%(2*np.pi))\n",
    "# #         return what_dict\n",
    "\n",
    "\n",
    "\n",
    "# def whats_this(par_dict):\n",
    "#         ''' you can tell that i hard coded this function :) '''\n",
    "#         what_dict = {}\n",
    "#         what_dict['r'] = np.exp(par_dict['lnr'])\n",
    "#         what_dict['e'] = 1 - np.exp(par_dict['eParam'])\n",
    "#         etta = np.arctan2(par_dict['sineta'],par_dict['coseta']) # *u.rad\n",
    "#         what_dict['eta'] = etta%(2*np.pi)\n",
    "#         what_dict['M'] = np.exp(par_dict['lnM'])\n",
    "#         allpha = np.arctan2(par_dict['sinalpha'],par_dict['cosalpha']) # *u.rad\n",
    "#         what_dict['alpha'] = allpha%(2*np.pi)\n",
    "#         return what_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats_this(lil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_pars = model.unpack_pars(sampler.chain[:, -1].T)\n",
    "# last_Lhatlg = coord.CartesianRepresentation(last_pars['Lhatlg'])\n",
    "# last_Lhatlg_sph = last_Lhatlg.represent_as(coord.UnitSphericalRepresentation)\n",
    "# plt.scatter(last_Lhatlg_sph.lon, last_Lhatlg_sph.lat)\n",
    "# plt.xlim(0, 2*np.pi)\n",
    "# plt.ylim(-np.pi, np.pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adrian conda",
   "language": "python",
   "name": "conda-adrian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
